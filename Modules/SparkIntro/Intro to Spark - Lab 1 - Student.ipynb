{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1 - Hello Spark\n",
    "This Lab will show you how to work with Apache Spark using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 1 - Working with Spark Context\n",
    "\n",
    "Step 1 - Invoke the spark context and extract what version of the spark driver application.\n",
    "\n",
    "Type<br>\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1.1 - Check spark version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 2 - Working with Resilient Distributed Datasets\n",
    "\n",
    "Step 2 - Create RDD with numbers 1 to 10,<br>\n",
    "Extract first line,<br>\n",
    "Extract first 5 lines,<br>\n",
    "Create RDD with string \"Hello Spark\",<br>\n",
    "Extract first line.<br>\n",
    "\n",
    "Type: <br>\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]<br>\n",
    "x_nbr_rdd = sc.parallelize(x)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 2.1 - Create RDD of Numbers 1-10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type: <br>\n",
    "x_nbr_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 2.2 - Extract first line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type:<br>\n",
    "x_nbr_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 2.3 - Extract first 5 lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type:<br>\n",
    "y = [\"Hello Spark!\"]<br>\n",
    "y_str_rdd = sc.parallelize(y)<br>\n",
    "y_str_rdd.first()<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 2.4 - Create String RDD, Extract first line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 3 - Count number of lines with Spark in it\n",
    "Step 3 - Pull in a spark README.md file, <br>\n",
    "Convert the file to an RDD,<br>\n",
    "Count the number of lines with the word \"Spark\" in it. <br>\n",
    "\n",
    "Type:<br>\n",
    "!wget https://github.com/bradenrc/Spark_POT/blob/master/Modules/SparkIntro/README.md<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-07-01 12:38:26--  https://github.com/bradenrc/Spark_POT/blob/master/Modules/SparkIntro/README.md\n",
      "Resolving github.com (github.com)... 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: 'README.md'\n",
      "\n",
      "    [ <=>                                   ] 41,094      --.-K/s   in 0.07s   \n",
      "\n",
      "2016-07-01 12:38:27 (590 KB/s) - 'README.md' saved [41094]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 3.1 - Pull data file into workbench\n",
    "!rm -r README.md.* rm -f README.md\n",
    "!wget https://github.com/bradenrc/Spark_POT/blob/master/Modules/SparkIntro/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type:<br>\n",
    "textfile_rdd = sc.textFile(\"README.md\")<br>\n",
    "textfile_rdd.first()<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 3.2 - Create RDD from data file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type:<br>\n",
    "spark_rdd = textfile_rdd.filter(lambda line: \"Spark\" in line)<br>\n",
    "spark_rdd.first()<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 3.3 - Filter for only lines with word Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type:<br>\n",
    "print \"The file README.md has \" + repr(spark_rdd.count()) + \" of \" + repr(textfile_rdd.count()) + \" Lines with word Spark in it.\"<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 3.4 - count the number of lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 4 - Perform analysis on a data file\n",
    "We have a sample file with instructors and scores. This exercise we want you to add all scores and report on results.\n",
    "\n",
    "Load File Instructor-Scores,<br>\n",
    "Map name and scores into RDD,<br>\n",
    "Add the 4 numbers per instructor,<br>\n",
    "Print the total score for each instructor<br>\n",
    "Print average score for each instructor<br>\n",
    "Who was top performer?<br>\n",
    "\n",
    "Data File Format: Name,Score1,Score2,Score3,Score4<br>\n",
    "Example Line: \"Carlo,5,3,3,4\"<br>\n",
    "Data File Location : https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/SparkIntro/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}